<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <title>Life RPG - pico.js</title>
    <script src="/lib/picojs/examples/camvas.js"></script>
    <script src="/lib/picojs/pico.js"></script>
    <!-- <script src="/lib/fps_meter.js"></script> -->
    <!--<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">-->
    <style>
      html,
      body {
        width: 100%;
        height: 100%;
        padding: 0;
        margin: 0;
      }
      .container {
        width: 1300px;
        margin: 0 auto;
      }
      .container h1 {
        display: block;
        text-align: center;
        margin-bottom: 1em;
      }
      .container canvas {
        margin: 0 auto;
      }
    </style>
  </head>
  <body>
    <div class="container">
      <h1>你就是天龍人la</h1>
      <canvas width="1280" height="720"></canvas>
    </div>
    <script>
      var initialized = false;
      //const meter = new FPSMeter();
      var img = new Image();
      img.onload = function() {
        initFaceDetect();
      };
      img.src = "./helmet_layer_2x.png";
      function initFaceDetect() {
        /*
      		(0) check whether we're already running face detection
      	*/
        if (initialized) return; // if yes, then do not initialize everything again
        /*
      		(1) initialize the pico.js face detector
      	*/
        var update_memory = pico.instantiate_detection_memory(5); // we will use the detecions of the last 5 frames
        var facefinder_classify_region = function(r, c, s, pixels, ldim) {
          return -1.0;
        };
        var cascadeurl = "/lib/picojs/model/facefinder";
        fetch(cascadeurl)
          .then(function(response) {
            return response.arrayBuffer();
          })
          .then(function(buffer) {
            var bytes = new Int8Array(buffer);
            facefinder_classify_region = pico.unpack_cascade(bytes);
            console.log("* facefinder loaded");
          });
        /*
      		(3) get the drawing context on the canvas and define a function to transform an RGBA image to grayscale
      	*/
        var ctx = document.getElementsByTagName("canvas")[0].getContext("2d");
        function rgba_to_grayscale(rgba, nrows, ncols) {
          var gray = new Uint8Array(nrows * ncols);
          for (var r = 0; r < nrows; ++r)
            for (var c = 0; c < ncols; ++c)
              // gray = 0.2*red + 0.7*green + 0.1*blue
              gray[r * ncols + c] =
                (2 * rgba[r * 4 * ncols + 4 * c + 0] +
                  7 * rgba[r * 4 * ncols + 4 * c + 1] +
                  1 * rgba[r * 4 * ncols + 4 * c + 2]) /
                10;
          return gray;
        }
        /*
      		(4) this function is called each time a video frame becomes available
      	*/
        var processfn = function(video, dt) {
          // render the video frame to the canvas element and extract RGBA pixel data
          ctx.drawImage(video, 0, 0);
          var rgba = ctx.getImageData(0, 0, 1280, 720).data;
          // prepare input to `run_cascade`
          image = {
            pixels: rgba_to_grayscale(rgba, 1280, 720),
            nrows: 720,
            ncols: 1280,
            ldim: 1280
          };
          params = {
            shiftfactor: 0.1, // move the detection window by 10% of its size
            minsize: 100, // minimum size of a face
            maxsize: 1000, // maximum size of a face
            scalefactor: 1.1 // for multiscale processing: resize the detection window by 10% when moving to the higher scale
          };
          // run the cascade over the frame and cluster the obtained detections
          // dets is an array that contains (r, c, s, q) quadruplets
          // (representing row, column, scale and detection score)
          dets = pico.run_cascade(image, facefinder_classify_region, params);
          dets = update_memory(dets);
          dets = pico.cluster_detections(dets, 0.2); // set IoU threshold to 0.2
          // draw detections
          // check the detection score
          // if it's above the threshold, draw it
          // (the constant 50.0 is empirical: other cascades might require a different one)
          for (face of dets) {
            if (face[3] > 50.0) {
              drawRegion(face);
            }
          }
          //meter.tick();
        };
        function drawRegion(face) {
          ctx.save();

          let width = face[2] * 2.1;
          let scalex = width / img.width;
          let scaley = width / img.height;

          let x = face[1] - width / 2;
          let y = face[0] - width / 2;
          ctx.translate(x, y);
          ctx.scale(scalex, scaley);

          ctx.drawImage(img, 0, 0);
          ctx.restore();
        }
        /*
      		(5) instantiate camera handling (see https://github.com/cbrandolino/camvas)
      	*/
        var mycamvas = new camvas(ctx, processfn);
        /*
      		(6) it seems that everything went well
      	*/
        initialized = true;
      }
    </script>
  </body>
</html>
